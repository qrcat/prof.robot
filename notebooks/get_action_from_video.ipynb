{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MUJOCO_GL'] = 'egl'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "if 'notebooks' not in os.listdir(os.getcwd()):\n",
    "    os.chdir('../') #changing directories so that output/gsplat_full etc. exists\n",
    "\n",
    "from collision.utils import DummyCam, ImageDemoDataset, generate_camera, put_pose_into_mujoco, update_reconstruction_dict, get_normalized_function\n",
    "from utils.mujoco_utils import compute_camera_extrinsic_matrix\n",
    "from scene.cameras import Camera_Pose\n",
    "from collision.chain_utils import build_chain_relation_map\n",
    "from collision.network import SingleNetwork, HyperNetwork\n",
    "from contextlib import redirect_stdout\n",
    "from video_api import initialize_gaussians\n",
    "\n",
    "import cv2\n",
    "from gaussian_renderer import render\n",
    "import sys \n",
    "import torch \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import mujoco\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from mujoco.usd import exporter\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from IPython.display import display, clear_output\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from typing import Dict\n",
    "import json\n",
    "\n",
    "\n",
    "class ImageDemoDataset(Dataset):\n",
    "    def __init__(self, data_path: Path, background_color):\n",
    "        self.cameras = sorted(data_path.glob(\"[0-9][0-9]\"))\n",
    "        self.camera_data = {}\n",
    "\n",
    "        for camera_path in self.cameras:\n",
    "            with (camera_path / \"camera.json\").open('r') as f:\n",
    "                camera_info = json.load(f)\n",
    "            self.camera_data[camera_path] = {\n",
    "                \"camera_info\": camera_info,\n",
    "                \"image\": sorted(camera_path.glob(\"[0-9][0-9][0-9][0-9].png\")),\n",
    "                \"mask\": sorted(camera_path.glob(\"seg_[0-9][0-9][0-9][0-9].png\")),\n",
    "                \"depth\": sorted(camera_path.glob(\"depth_[0-9][0-9][0-9][0-9].npy\")),\n",
    "            }\n",
    "\n",
    "        self.action = np.load(data_path / \"qpos.npy\")\n",
    "\n",
    "        self.preprocess = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        self.background_tuple = background_color\n",
    "    \n",
    "    def __getitem__(self, index) -> Dict[str, torch.Tensor]:\n",
    "        camera_list = []\n",
    "        image_list = []\n",
    "        mask_list = []\n",
    "        depth_list = []\n",
    "\n",
    "        for camera_data in self.camera_data.values():\n",
    "            camera_list.append(camera_data['camera_info'])\n",
    "\n",
    "            image = Image.open(camera_data['image'][index])\n",
    "            seg = Image.open(camera_data['mask'][index])\n",
    "            bg = Image.new(\"RGB\", image.size, self.background_tuple)\n",
    "            depth = np.load(camera_data['depth'][index]) * np.asarray(seg)\n",
    "\n",
    "            result = Image.composite(image, bg, seg)\n",
    "\n",
    "            image_list.append(self.preprocess(result).float())\n",
    "            mask_list.append(self.preprocess(seg).float())\n",
    "            depth_list.append(torch.as_tensor(depth).float())\n",
    "        \n",
    "        return {\n",
    "            \"action\": self.action[index],\n",
    "            \"camera\": camera_list,\n",
    "            \"image\": image_list,\n",
    "            \"mask\": mask_list,\n",
    "            \"depth\": depth_list,\n",
    "        }\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.action.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['']\n",
    "gaussians, background_color, sample_cameras, kinematic_chain = initialize_gaussians(model_path='output/universal_robots_ur5e_robotiq')\n",
    "kinematic_chain.to(device='cuda', dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mujoco\n",
    "model = mujoco.MjModel.from_xml_path(\"mujoco_demo_control/universal_robots_ur5e_robotiq/scene.xml\")\n",
    "data = mujoco.MjData(model)\n",
    "\n",
    "mujoco.mj_resetData(model, data)\n",
    "\n",
    "\n",
    "def sample_collision_pose():\n",
    "    pose = np.random.uniform(model.jnt_range[:, 0], model.jnt_range[:, 1])\n",
    "    put_pose_into_mujoco(model, data, pose)\n",
    "    return pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_tuple = (255, 255, 255)\n",
    "\n",
    "demo_ds = ImageDemoDataset(Path(\"output/demonstration/universal_robots_ur5e_robotiq\"), background_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(480, 480), dpi=1)\n",
    "plt.imshow(demo_ds[120]['depth'][2])\n",
    "plt.axis('off')\n",
    "plt.subplots_adjust(0, 0, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_resetData(model, data)\n",
    "\n",
    "# set camera\n",
    "dummy_cams = [\n",
    "    DummyCam(0, -00.0, 2.5, lookat=[0,  0, 0]),\n",
    "    DummyCam(0, -10.0, 2.5, lookat=[0,  0, 0]),\n",
    "    DummyCam(0, 170, 2.5, lookat=[0,  0, 0]),\n",
    "]\n",
    "cams = [generate_camera(dummy_cam) for dummy_cam in dummy_cams]\n",
    "\n",
    "renderer = mujoco.Renderer(model, 480, 480)\n",
    "renderer.update_scene(data, camera=cams[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_step(model, data, 1000)\n",
    "\n",
    "renderer.update_scene(data, camera=cams[0])\n",
    "pixels = renderer.render()\n",
    "image = Image.fromarray(pixels)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_map, chain = build_chain_relation_map(\"mujoco_menagerie/universal_robots_ur5e_robotiq/scene.xml\")\n",
    "sdf_model = HyperNetwork(6, relation_map)\n",
    "state_dict = torch.load(\"output/universal_robots_ur5e_robotiq/sdf_net.ckpt\", weights_only=True)\n",
    "sdf_model.load_state_dict(state_dict)\n",
    "for parameters in sdf_model.parameters():\n",
    "    parameters.requires_grad_(False)\n",
    "sdf_model.cuda()\n",
    "del state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_fun, unnorm_fun = get_normalized_function(*kinematic_chain.get_joint_limits())\n",
    "\n",
    "init_params = [0.0] * 14\n",
    "joint_angles = torch.nn.Parameter(\n",
    "    torch.tensor(init_params, dtype=torch.float32, device='cuda')\n",
    ")\n",
    "optimizer = torch.optim.Adam([joint_angles], lr=0.01)\n",
    "\n",
    "\n",
    "background_tuple = (255, 255, 255)\n",
    "bg_color_t = torch.tensor(background_tuple).float().cuda() / 255.0\n",
    "\n",
    "cam_list = []\n",
    "\n",
    "for dummy_cam in dummy_cams:\n",
    "    camera_extrinsic_matrix = compute_camera_extrinsic_matrix(dummy_cam)\n",
    "    cam_list.append(\n",
    "        Camera_Pose(torch.tensor(camera_extrinsic_matrix).clone().detach().float().cuda(), 0.78, 0.78, 480, 480, joint_pose=norm_fun(joint_angles), zero_init=True).cuda()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(gaussians, joint_params, opt, background_color, gt_pkg: dict, norm_fun, max_iteration=200, callback=None):\n",
    "    bg_color_t = torch.tensor(background_color).float().cuda() / 255.0\n",
    "\n",
    "    camera_list, image_list, depth_list, gt_action = gt_pkg[\"camera\"], gt_pkg[\"image\"], gt_pkg[\"depth\"], gt_pkg['action']\n",
    "\n",
    "    image_list = [image.cuda() for image in image_list]\n",
    "    depth_list = [depth.cuda() for depth in depth_list]\n",
    "\n",
    "    gt_action = torch.tensor(gt_action[:14], dtype=torch.float32, device='cuda')\n",
    "\n",
    "    def get_gs_camera(camera_info: dict):\n",
    "        dummy_cam = DummyCam(camera_info['azimuth'], camera_info['elevation'], camera_info['distance'], lookat=camera_info['lookat'])\n",
    "        camera_extrinsic_matrix = compute_camera_extrinsic_matrix(dummy_cam)\n",
    "        return Camera_Pose(torch.tensor(camera_extrinsic_matrix).clone().detach().float().cuda(), 0.78, 0.78, 480, 480, joint_pose=norm_fun(joint_params), zero_init=True).cuda()\n",
    "    \n",
    "    camera_list = [get_gs_camera(camera_info) for camera_info in camera_list]\n",
    "\n",
    "    camera_pkg = cycle(zip(camera_list, image_list, depth_list))\n",
    "    \n",
    "    tbar = trange(max_iteration, leave=False)\n",
    "    for iteration in tbar:\n",
    "        camera, gt_image, gt_depth = next(camera_pkg)\n",
    "\n",
    "        camera.joint_pose = norm_fun(joint_params)\n",
    "        output_pkg = render(camera, gaussians, bg_color_t)\n",
    "        image_tensor = output_pkg['render']\n",
    "        depth_tensor = output_pkg['depth']\n",
    "        \n",
    "        mask = gt_depth > 0\n",
    "        Ll1_seg = F.l1_loss(image_tensor[:, mask], gt_image[:, mask])\n",
    "        Ldepth_seg = F.l1_loss(depth_tensor[mask], gt_depth[mask])\n",
    "\n",
    "        loss = Ll1_seg + Ldepth_seg\n",
    "\n",
    "        loss = loss / len(camera_list)\n",
    "        loss.backward()\n",
    "\n",
    "        if iteration % len(camera_list) == len(camera_list)-1:\n",
    "            if callback is not None:\n",
    "                callback()\n",
    "\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topil = transforms.ToPILImage()\n",
    "\n",
    "@torch.no_grad()\n",
    "def render_image(gaussians, joint_params, background_color, gt_pkg: dict, norm_fun, idx=0):\n",
    "    bg_color_t = torch.tensor(background_color).float().cuda() / 255.0\n",
    "\n",
    "    camera, gt_image, gt_depth, gt_action = gt_pkg[\"camera\"][idx], gt_pkg[\"image\"][idx], gt_pkg[\"depth\"][idx], gt_pkg['action']\n",
    "\n",
    "    image_list = gt_image.cuda()\n",
    "    depth_list = gt_depth.cuda()\n",
    "\n",
    "    gt_action = torch.tensor(gt_action[:14], dtype=torch.float32, device='cuda')\n",
    "\n",
    "    def get_gs_camera(camera_info: dict):\n",
    "        dummy_cam = DummyCam(camera_info['azimuth'], camera_info['elevation'], camera_info['distance'], lookat=camera_info['lookat'])\n",
    "        camera_extrinsic_matrix = compute_camera_extrinsic_matrix(dummy_cam)\n",
    "        return Camera_Pose(torch.tensor(camera_extrinsic_matrix).clone().detach().float().cuda(), 0.78, 0.78, 480, 480, joint_pose=norm_fun(joint_params), zero_init=True).cuda()\n",
    "    \n",
    "    camera = get_gs_camera(camera)\n",
    "\n",
    "    camera.joint_pose = norm_fun(joint_params)\n",
    "    output_pkg = render(camera, gaussians, bg_color_t)\n",
    "    image_tensor = output_pkg['render']\n",
    "    depth_tensor = output_pkg['depth']\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display(topil(image_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_actions = []\n",
    "# init joint angle to zero\n",
    "with torch.no_grad():\n",
    "    joint_angles[:] = 0\n",
    "# optimize angle\n",
    "for iteration, data_pkg in enumerate(tqdm(demo_ds)):\n",
    "    optimize(gaussians, \n",
    "             joint_angles,\n",
    "             optimizer, \n",
    "             background_tuple, \n",
    "             data_pkg,\n",
    "             norm_fun,\n",
    "             max_iteration=3*5,\n",
    "             )\n",
    "    inverse_actions.append(joint_angles.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration, (data_pkg, joint_angle) in enumerate(zip(demo_ds, inverse_actions)):\n",
    "    render_image(gaussians, \n",
    "                 torch.tensor(joint_angle, device='cuda'),\n",
    "                 background_tuple, \n",
    "                 data_pkg,\n",
    "                 norm_fun,\n",
    "                 idx=0)\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_resetData(model, data)\n",
    "mujoco.mj_step(model, data, 1000)\n",
    "init_collison = data.ncon\n",
    "collision_list = []\n",
    "for iteration, action in enumerate(tqdm(inverse_actions)):\n",
    "    data.qpos[:6] = action[:6]\n",
    "    mujoco.mj_step(model, data)\n",
    "    mujoco.mj_collision(model, data)\n",
    "    collision_list.append(data.ncon)\n",
    "collision_list = np.asarray(collision_list) - init_collison\n",
    "print('collision', np.mean(collision_list), np.mean(collision_list>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_resetData(model, data)\n",
    "mujoco.mj_step(model, data, 1000)\n",
    "\n",
    "exp = exporter.USDExporter(model=model)\n",
    "\n",
    "last_gripper = 0\n",
    "for iteration, action in enumerate(tqdm(inverse_actions)):\n",
    "    data.ctrl[:6] = action[:6]\n",
    "    if (action[6]+action[8]) > 0.6:\n",
    "        data.ctrl[6] = 255\n",
    "\n",
    "    renderer.update_scene(data, camera=cams[0])\n",
    "    exp.update_scene(data=data)\n",
    "\n",
    "    pixels = renderer.render()\n",
    "    \n",
    "    image = Image.fromarray(pixels)\n",
    "    clear_output(wait=True)\n",
    "    display(image)\n",
    "    \n",
    "    mujoco.mj_step(model, data, 10)\n",
    "    mujoco.mj_collision(model, data)\n",
    "\n",
    "    time.sleep(0.05)\n",
    "exp.save_scene(filetype=\"usd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_action = torch.nn.Parameter(torch.tensor(inverse_actions, device='cuda', dtype=torch.float))\n",
    "target_opt = torch.optim.Adam([target_action], lr=0.001)\n",
    "init_joint_angle = torch.zeros_like(joint_angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbar = tqdm(demo_ds, leave=False)\n",
    "for iteration, data_pkg in enumerate(tbar):\n",
    "    def tv_loss():\n",
    "        if iteration == 0:\n",
    "            tv_loss = torch.nn.functional.l1_loss(target_action[0], target_action[1].detach())\n",
    "        elif iteration == len(demo_ds) - 1:\n",
    "            tv_loss = torch.nn.functional.l1_loss(target_action[iteration], target_action[iteration-1].detach())\n",
    "        else:\n",
    "            tv_loss = torch.nn.functional.l1_loss(target_action[iteration], target_action[iteration-1].detach()) + torch.nn.functional.l1_loss(target_action[iteration], target_action[iteration+1].detach())\n",
    "            tv_loss = tv_loss / 2\n",
    "                        \n",
    "        tv_loss = tv_loss * 0.001\n",
    "        tv_loss.backward()\n",
    "\n",
    "    target_opt.zero_grad()\n",
    "\n",
    "    loss = optimize(gaussians, \n",
    "                    target_action[iteration],\n",
    "                    target_opt,\n",
    "                    background_tuple, \n",
    "                    data_pkg,\n",
    "                    norm_fun,\n",
    "                    3*10,\n",
    "                    callback=tv_loss\n",
    "                    )\n",
    "    \n",
    "    tbar.set_postfix(\n",
    "        {   \n",
    "            \"Iteration\": iteration,\n",
    "            \"Loss\": loss.item(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    target_opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    target_action_s0 = target_action.clone().detach()\n",
    "target_action_s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_resetData(model, data)\n",
    "mujoco.mj_step(model, data, 1000)\n",
    "\n",
    "exp = exporter.USDExporter(model=model)\n",
    "last_gripper = 0\n",
    "for iteration, action in enumerate(tqdm(target_action_s0.cpu().numpy())):\n",
    "    data.ctrl[:6] = action[:6]\n",
    "    if (action[6]+action[8]) > 0.6:\n",
    "        data.ctrl[6] = 255\n",
    "\n",
    "    renderer.update_scene(data, camera=cams[0])\n",
    "    exp.update_scene(data=data)\n",
    "\n",
    "    pixels = renderer.render()\n",
    "    \n",
    "    image = Image.fromarray(pixels)\n",
    "    clear_output(wait=True)\n",
    "    display(image)\n",
    "    \n",
    "    mujoco.mj_step(model, data, 10)\n",
    "    mujoco.mj_collision(model, data)\n",
    "\n",
    "    time.sleep(0.05)\n",
    "exp.save_scene(filetype=\"usd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use ee pose as constrict\n",
    "with torch.no_grad():\n",
    "    target_ee_pose = kinematic_chain.forward_kinematics(target_action_s0)['ur5e_0_wrist_3_link'].get_matrix().detach()\n",
    "\n",
    "    plt.plot(target_action_s0[:, 6].detach().cpu().numpy())\n",
    "ee_start = torch.nonzero(target_action_s0[:, 6] > 0.5)[0] - 20\n",
    "ee_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_opt.zero_grad()\n",
    "with torch.no_grad():\n",
    "    target_action[:] = target_action_s0\n",
    "target_opt = torch.optim.Adam([target_action], lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbar = trange(10000)\n",
    "for i in tbar:\n",
    "    sdf_loss = torch.relu(sdf_model(target_action[:ee_start])[0]+0.10).mean()\n",
    "\n",
    "    # ee pose\n",
    "    ee_pose = kinematic_chain.forward_kinematics(target_action)['ur5e_0_wrist_3_link'].get_matrix()\n",
    "\n",
    "    # xyz reconstriction for ee pose\n",
    "    ee_tsl_loss = (ee_pose[ee_start:, :3, 3:]-target_ee_pose[ee_start:, :3, 3:]).norm(dim=-1).mean()\n",
    "    ee_tv_loss = (ee_pose[1:, :3, 3:]-ee_pose[:-1, :3, 3:]).norm(dim=-1).mean()\n",
    "\n",
    "    # TV loss\n",
    "    tv_loss =  (target_action[1:]-target_action[:-1]).norm(dim=-1).mean()\n",
    "    \n",
    "    # movement\n",
    "    move_loss = torch.nn.functional.mse_loss(target_action, target_action_s0)\n",
    "\n",
    "    loss = 10.0 * sdf_loss + 10.0 * ee_tsl_loss + 1.0 * ee_tv_loss + 1.0 * tv_loss + 0.001 * move_loss\n",
    "    # loss = loss * 100\n",
    "    loss.backward()\n",
    "    target_opt.step()\n",
    "\n",
    "    tbar.set_postfix(\n",
    "        {   \n",
    "            \"Loss\": format(loss.item() ,\"3.3e\"),\n",
    "            \"SDF\": format(sdf_loss.item(), \".4f\"),\n",
    "            \"EET\": format(ee_tsl_loss.item(), \".4f\"),\n",
    "            \"ETV\": format(ee_tv_loss.item(), \".4f\"),\n",
    "            \"TV\": format(tv_loss.item(), \".4f\"),\n",
    "            \"MOVE\": format(move_loss.item(), \".4f\"),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_action.grad.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_resetData(model, data)\n",
    "mujoco.mj_step(model, data, 1000)\n",
    "init_collison = data.ncon\n",
    "data.qpos[14:-1] = 0.9\n",
    "collision_list = []\n",
    "for iteration, action in enumerate(tqdm(target_action.detach().cpu().numpy())):\n",
    "    data.qpos[:6] = action[:6]\n",
    "    mujoco.mj_step(model, data)\n",
    "    mujoco.mj_collision(model, data)\n",
    "    collision_list.append(data.ncon)\n",
    "collision_list = np.asarray(collision_list) - init_collison\n",
    "print('collision', np.mean(collision_list), np.mean(collision_list>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_resetData(model, data)\n",
    "mujoco.mj_step(model, data, 1000)\n",
    "last_gripper = 0\n",
    "\n",
    "exp = exporter.USDExporter(model=model)\n",
    "\n",
    "for iteration, action in enumerate(tqdm(target_action.detach().cpu().numpy())):\n",
    "    data.ctrl[:6] = action[:6]\n",
    "    if action[6] > 0.6 and last_gripper == 0:\n",
    "        last_gripper = 255\n",
    "\n",
    "    data.ctrl[6] = last_gripper\n",
    "\n",
    "    renderer.update_scene(data, camera=cams[0])\n",
    "    exp.update_scene(data=data)\n",
    "\n",
    "    pixels = renderer.render()\n",
    "    \n",
    "    image = Image.fromarray(pixels)\n",
    "    clear_output(wait=True)\n",
    "    display(image)\n",
    "    \n",
    "    mujoco.mj_step(model, data, 10)\n",
    "    mujoco.mj_collision(model, data)\n",
    "\n",
    "    time.sleep(0.05)\n",
    "exp.save_scene(filetype=\"usd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "put_pose_into_mujoco(model, data, joint_angles.detach().cpu().numpy())\n",
    "print(data.ncon)\n",
    "renderer.update_scene(data, camera=cams[0])\n",
    "pixels = renderer.render()\n",
    "image = Image.fromarray(pixels)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.jnt_range[:6, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_list = []\n",
    "\n",
    "for i in range(100000):\n",
    "    pose = np.random.uniform(\n",
    "        np.array([np.pi/2, -np.pi, -np.pi, 0, 0, 0]), \n",
    "        np.array([np.pi/2,  np.pi,  np.pi, 0, 0, 0]))\n",
    "    \n",
    "    pose_list.append(pose[:6])\n",
    "pose_list = np.asarray(pose_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_pose = pose_list[1000]\n",
    "mujoco.mj_resetData(model, data)\n",
    "data.qpos[:6] = pose_list[300]\n",
    "data.qpos[-3:] = [0, 0, 10]\n",
    "mujoco.mj_step(model, data)\n",
    "print(data.ncon)\n",
    "\n",
    "renderer.update_scene(data, camera=cams[1])\n",
    "pixels = renderer.render()\n",
    "image = Image.fromarray(pixels)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_pose = pose_list[:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf, s = sdf_model(torch.tensor(pose_list, dtype=torch.float32, device='cuda'))\n",
    "sdf.max(), sdf.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(xy_pose[:, 0], xy_pose[:, 1], c=sdf.detach().cpu().numpy()[:, 0], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "\n",
    "scale = 0.1\n",
    "\n",
    "grid_x, grid_y = np.mgrid[-scale:scale:100j, -scale:scale:100j]  # 100j表示在0到10之间创建100个\n",
    "grid_x -= 2.7\n",
    "grid_y -= 1.5\n",
    "grid_z = griddata((xy_pose[:, 0], xy_pose[:, 1]), sdf.detach().cpu().numpy()[:, 0], (grid_x, grid_y), method='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.contourf(grid_x, grid_y, grid_z, origin='lower', cmap='viridis')\n",
    "# C = plt.contour(grid_x, grid_y, grid_z, colors ='black', linestyles='solid', linewidths=1)\n",
    "plt.axis('off')\n",
    "# plt.scatter(*xy_pose[34], c='r')\n",
    "# plt.scatter(new_xy_p[:, 0], new_xy_p[:, 1], c='r')\n",
    "plt.scatter(init_pose[1], init_pose[2], c='r')\n",
    "plt.scatter(traj_stack[:, 1], traj_stack[:, 2], c='b')\n",
    "plt.clabel(C, inline=True, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nonzero((sdf.abs() > 0.1) & (sdf < 0.2))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 99686\n",
    "\n",
    "print(xy_pose[i], sdf[i], pose_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero((xy_pose[:, 0] < -2.25) & (xy_pose[:, 0] > -3) & (xy_pose[:, 1] < -0.75) & (xy_pose[:, 1] > -1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_list[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_resetData(model, data)\n",
    "\n",
    "# set camera\n",
    "dummy_cams = [\n",
    "    DummyCam(0, -00.0, 2.5, lookat=[0,  0, 0]),\n",
    "    DummyCam(0, -10.0, 2.5, lookat=[0,  0, 0]),\n",
    "    DummyCam(180, -20, 2, lookat=[0,  0, 0]),\n",
    "]\n",
    "cams = [generate_camera(dummy_cam) for dummy_cam in dummy_cams]\n",
    "\n",
    "renderer = mujoco.Renderer(model, 480, 480)\n",
    "renderer.update_scene(data, camera=cams[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_resetData(model, data)\n",
    "data.qpos[:6] = traj_stack[4]\n",
    "data.qpos[-3:] = [0, 0, 1]\n",
    "mujoco.mj_step(model, data)\n",
    "print(data.ncon)\n",
    "\n",
    "exp = exporter.USDExporter(model=model)\n",
    "exp.update_scene(data=data)\n",
    "exp.save_scene(filetype=\"usd\")\n",
    "renderer.update_scene(data, camera=cams[2])\n",
    "pixels = renderer.render()\n",
    "image = Image.fromarray(pixels)\n",
    "image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_stack[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_pose = np.array([1.5008376, -2.727698, -1.5297332, -0.0697833, 0.06970214, -0.06995709])\n",
    "init_pose_t = torch.nn.Parameter(torch.tensor(init_pose, dtype=torch.float32, device='cuda'))\n",
    "optimizer = torch.optim.Adam([init_pose_t], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_stack = []\n",
    "# SDF Loss \n",
    "for i in trange(1000):\n",
    "    if (i % 2 == 0) and (i>0):\n",
    "        traj_stack.append(init_pose_t.detach().cpu().numpy())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    sdf, s = sdf_model(init_pose_t[None])\n",
    "    sdf.backward()\n",
    "    optimizer.step()\n",
    "    print(i, sdf)\n",
    "    \n",
    "    if sdf < 0.5:\n",
    "        break\n",
    "print(len(traj_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_stack = np.asarray(traj_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_model(init_pose_t[None])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_stack[0]-init_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mujoco.mj_resetData(model, data)\n",
    "data.qpos[:6] = init_pose\n",
    "data.qpos[-3:] = [0, 0, 10]\n",
    "mujoco.mj_step(model, data)\n",
    "print(data.ncon)\n",
    "renderer.update_scene(data, camera=cams[2])\n",
    "pixels = renderer.render()\n",
    "image = Image.fromarray(pixels)\n",
    "image\n",
    "# data.ncon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.contourf(grid_x, grid_y, grid_z, origin='lower', cmap='viridis')\n",
    "C = plt.contour(grid_x, grid_y, grid_z, colors ='black', linestyles='solid', linewidths=1)\n",
    "plt.axis('off')\n",
    "# plt.scatter(*xy_pose[75291], c='r')\n",
    "plt.scatter(traj_stack[:, 1], traj_stack[:, 2], c='r')\n",
    "plt.clabel(C, inline=True, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_z = grid_z.T[10:90, 10:90] * 0.5\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "plt.contourf(plt_z, [-1, -0.75, -0.5, 0.0, 0.25, 0.5, 0.75, 1, 1.25], origin='lower', cmap='viridis')\n",
    "C = plt.contour(plt_z, [-0.5, 0.0, 0.5], colors ='black', linestyles='solid', linewidths=5)\n",
    "plt.axis('off')\n",
    "plt.clabel(C, inline=True, fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
